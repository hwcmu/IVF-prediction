# -*- coding: utf-8 -*-
"""Embedding

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kzYhGzP6PzzZEHy8vJo9vQRw-woEi1CK
"""

import pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV
from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, precision_score, recall_score

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# --- 1. Data Loading Function ---

def safe_load_data(file_path):
    """
    Safely loads a pickle file.
    """
    try:
        with open(file_path, "rb") as f:
            data = pickle.load(f)
        if 'ids' not in data and 'target' in data:
            n_samples = len(data['target'])
            data['ids'] = np.arange(n_samples)
        return data
    except FileNotFoundError:
        print(f"Error: Data file not found at {file_path}.")
        return None
    except Exception as e:
        print(f"An error occurred while loading {file_path}: {e}")
        return None

# --- 2. Core Modeling and Evaluation Functions ---

def run_cv_tuned(model_type, features, labels, id_array, n_splits=5):
    """
    Performs K-Fold cross-validation with hyperparameter tuning.
    For GBC, it uses RandomizedSearchCV to accelerate the training process.
    """
    if model_type == 'lr':
        base_model = LogisticRegression(random_state=42, max_iter=5000)
        param_grid = {
            'C': [0.01, 0.1, 1, 10], 'penalty': ['l2'], 'solver': ['lbfgs']
        }
        searcher = GridSearchCV(base_model, param_grid, cv=3, scoring='roc_auc', n_jobs=-1)

    elif model_type == 'gbc':
        base_model = GradientBoostingClassifier(random_state=42)
        param_dist = {
            'n_estimators': [50, 100, 200, 300],
            'learning_rate': [0.05, 0.1, 0.2],
            'max_depth': [3, 5, 8],
            'subsample': [0.8, 0.9, 1.0],
            'max_features': ['sqrt', 'log2', None]
        }
        searcher = RandomizedSearchCV(
            base_model, param_distributions=param_dist, n_iter=20, cv=3,
            scoring='roc_auc', n_jobs=-1, random_state=42
        )
    else:
        raise ValueError("model_type must be 'lr' or 'gbc'")

    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)
    all_ids, all_true_labels, all_pred_probs = [], [], []

    for train_idx, val_idx in kf.split(features):
        X_train, X_val = features[train_idx], features[val_idx]
        y_train = labels.iloc[train_idx].values if hasattr(labels, 'iloc') else labels[train_idx]
        y_val = labels.iloc[val_idx].values if hasattr(labels, 'iloc') else labels[val_idx]

        searcher.fit(X_train, y_train)
        best_model = searcher.best_estimator_
        pred_probs = best_model.predict_proba(X_val)[:, 1]

        all_ids.extend(id_array[val_idx])
        all_true_labels.extend(y_val)
        all_pred_probs.extend(pred_probs)

    return pd.DataFrame({
        'ID': all_ids,
        'True_Label': all_true_labels,
        'Predicted_Probability': all_pred_probs
    })

def find_optimal_cutoff(y_true, y_pred_prob):
    """Finds the optimal probability cutoff point."""
    fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)
    optimal_idx = np.argmin(np.sqrt((1 - tpr)**2 + fpr**2))
    return thresholds[optimal_idx], fpr, tpr

def calculate_metrics(y_true, y_pred_prob, threshold):
    """Calculates classification metrics for a given threshold."""
    y_pred = (y_pred_prob >= threshold).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    return {
        'accuracy': accuracy_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred, zero_division=0),
        'sensitivity': recall_score(y_true, y_pred, zero_division=0),
        'specificity': tn / (tn + fp) if (tn + fp) > 0 else 0
    }

# --- 3. Main Analysis Workflow ---

def perform_analysis(model_type, datasets):
    """
    Main function to run the complete analysis for a given model type.
    It now plots a single figure with three subplots.
    """
    print(f"\n{'='*80}")
    print(f" Starting Analysis for: {model_type.upper()} ".center(80, '='))
    print(f"{'='*80}\n")

    model_name_map = {'lr': 'Logistic Regression', 'gbc': 'Gradient Boosting'}
    model_name = model_name_map.get(model_type, "Unknown Model")

    all_results = {}
    embedding_list = ['gpt2', 'countvectorizer', 'word2vec']

    for method_name in embedding_list:
        data = datasets.get(method_name)
        if data is None:
            print(f"Skipping {method_name} as data is not loaded.")
            continue
        print(f"Processing {model_name} on {method_name.upper()} embeddings...")
        method_results = {}
        method_results['structured'] = run_cv_tuned(model_type, data['structured_data'], data['target'], data['ids'])
        method_results['unstructured'] = run_cv_tuned(model_type, data['text_embeddings'], data['target'], data['ids'])
        method_results['combined'] = run_cv_tuned(model_type, np.hstack([data['structured_data'], data['text_embeddings']]), data['target'], data['ids'])
        all_results[method_name] = method_results
        print(f"Finished with {method_name.upper()} embeddings.")

    results_summary = []
    roc_data_all = {}
    for method_name, method_results in all_results.items():
        for feature_type, df in method_results.items():
            y_true = df['True_Label']
            y_pred_prob = df['Predicted_Probability']
            opt_thresh, fpr, tpr = find_optimal_cutoff(y_true, y_pred_prob)
            roc_auc = auc(fpr, tpr)
            metrics = calculate_metrics(y_true, y_pred_prob, opt_thresh)
            summary_row = {'Method': method_name, 'Feature_Type': feature_type, 'AUC': roc_auc, **metrics, 'Optimal_Threshold': opt_thresh}
            results_summary.append(summary_row)
            roc_data_all[f"{method_name}_{feature_type}"] = {'fpr': fpr, 'tpr': tpr, 'auc': roc_auc}

    results_df = pd.DataFrame(results_summary)
    output_csv = f"{model_type}_full_comparison.csv"
    results_df.to_csv(output_csv, index=False)
    print(f"\nComprehensive results for {model_name} saved to '{output_csv}'")
    print(results_df[['Method', 'Feature_Type', 'AUC', 'Accuracy']].round(4))

    if not roc_data_all:
        print("\nNo data available to plot.")
        return

    print("\nGenerating ROC curve plots...")
    fig, axes = plt.subplots(1, 3, figsize=(24, 7), sharey=True)
    fig.suptitle(f'ROC Curves for {model_name} Models by Embedding Type', fontsize=18)
    feature_colors = {'structured': 'blue', 'unstructured': 'green', 'combined': 'red'}

    for i, method in enumerate(embedding_list):
        ax = axes[i]
        if method not in all_results:
            ax.text(0.5, 0.5, f'{method} data not loaded', ha='center', va='center', fontsize=12)
            ax.set_title(f'{method.title()} Embeddings')
            continue

        for feature_type in ['structured', 'unstructured', 'combined']:
            combo_name = f"{method}_{feature_type}"
            if combo_name in roc_data_all:
                roc_info = roc_data_all[combo_name]
                ax.plot(roc_info['fpr'], roc_info['tpr'], color=feature_colors[feature_type], lw=2,
                        label=f'{feature_type.title()} (AUC = {roc_info["auc"]:.3f})')

        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        ax.set_xlim([0.0, 1.0])
        ax.set_ylim([0.0, 1.05])
        ax.set_xlabel('False Positive Rate', fontsize=12)
        ax.set_ylabel('True Positive Rate' if i == 0 else '', fontsize=12)
        ax.set_title(f'{method.title()} Embeddings', fontsize=14)
        ax.legend(loc="lower right")
        ax.grid(alpha=0.4)

    plt.tight_layout(rect=[0, 0, 1, 0.95])
    output_png = f"{model_type}_roc_curves_combined.png"
    plt.savefig(output_png, dpi=300)
    plt.close()
    print(f"--- Combined ROC curve plot saved to '{output_png}' ---")

# --- 4. Main Execution Block ---

if __name__ == "__main__":
    # --- Define which datasets to load ---
    datasets_to_load = {
        'gpt2': 'processed_data.pkl',
        'countvectorizer': 'countvectorizer_model_input_data.pkl',
        'word2vec': 'word2vec_model_input_data.pkl'
    }

    print("Loading specified data files...")
    datasets = {name: safe_load_data(path) for name, path in datasets_to_load.items()}

    # --- Run Analyses if data was loaded successfully ---
    if any(v is not None for v in datasets.values()):
        print("\nData loaded successfully!")

        perform_analysis('lr', datasets)
        perform_analysis('gbc', datasets)

        print(f"\n{'='*80}")
        print(" All Analyses Complete ".center(80, '='))
        print(f"{'='*80}\n")
    else:
        print("\nCritical Error: No data files could be loaded. Aborting analysis.")
```eof