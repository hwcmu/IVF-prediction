{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1984b6bcd45e4f1e897cd28a598f40ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90b9a960950a4ef8a26a79a291f9549e",
              "IPY_MODEL_0d258d6f23194fc69b42ca1ceb954120",
              "IPY_MODEL_3f8fbd831c0f45cea8494a1878100c38"
            ],
            "layout": "IPY_MODEL_19dfb48eb79f40e6a130fe6537209110"
          }
        },
        "90b9a960950a4ef8a26a79a291f9549e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dffa9442f3124d3dafdc8428d41d14c2",
            "placeholder": "​",
            "style": "IPY_MODEL_2c67947a2ae54beeb530e4cd251f654d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0d258d6f23194fc69b42ca1ceb954120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b5ec33d10ad4a6688d9a88776926b44",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80faeecb00204042b9cf7e1f98be6e17",
            "value": 26
          }
        },
        "3f8fbd831c0f45cea8494a1878100c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fafbe524d924c8384995c9c65da92ba",
            "placeholder": "​",
            "style": "IPY_MODEL_9a2812663fb34cbfb48302e577c11ce0",
            "value": " 26.0/26.0 [00:00&lt;00:00, 2.27kB/s]"
          }
        },
        "19dfb48eb79f40e6a130fe6537209110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dffa9442f3124d3dafdc8428d41d14c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c67947a2ae54beeb530e4cd251f654d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b5ec33d10ad4a6688d9a88776926b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80faeecb00204042b9cf7e1f98be6e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fafbe524d924c8384995c9c65da92ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a2812663fb34cbfb48302e577c11ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd030dd1a489475685f6f4de38097099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_206314163af3424d9af43e0633eb0002",
              "IPY_MODEL_b4702bdce56f419188224e478f6e2cb1",
              "IPY_MODEL_ea58a7323d094d97ad875c39f6b88b8f"
            ],
            "layout": "IPY_MODEL_8c82823903d142f88e559e1a3806c565"
          }
        },
        "206314163af3424d9af43e0633eb0002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_658969ba784f445f95a546aed01ffe6c",
            "placeholder": "​",
            "style": "IPY_MODEL_379518442f26437ca9681b1793cc52dd",
            "value": "vocab.json: 100%"
          }
        },
        "b4702bdce56f419188224e478f6e2cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe00587bd0d84083970f1a05a48af5f8",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7358673defd243bf92aa7c27edc6e737",
            "value": 1042301
          }
        },
        "ea58a7323d094d97ad875c39f6b88b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77b133b698a342d7ae1f2d7cb1bc165c",
            "placeholder": "​",
            "style": "IPY_MODEL_17421287133b436b8a66fb1581ebd177",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.18MB/s]"
          }
        },
        "8c82823903d142f88e559e1a3806c565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "658969ba784f445f95a546aed01ffe6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "379518442f26437ca9681b1793cc52dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe00587bd0d84083970f1a05a48af5f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7358673defd243bf92aa7c27edc6e737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77b133b698a342d7ae1f2d7cb1bc165c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17421287133b436b8a66fb1581ebd177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e51698dbf1a44a88d949ef284348f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7be8de019ae34c46beaa1d57532c819f",
              "IPY_MODEL_b1faed6c572c47069fb32dce28f4a264",
              "IPY_MODEL_bb5a340a49be491590f29cd2e9b91d68"
            ],
            "layout": "IPY_MODEL_cff28fd85c7b425ca34614c6c4c77598"
          }
        },
        "7be8de019ae34c46beaa1d57532c819f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ff03b6bc7774baa8236af7d5f75440f",
            "placeholder": "​",
            "style": "IPY_MODEL_fb19b734194648cfb234c180a0276762",
            "value": "merges.txt: 100%"
          }
        },
        "b1faed6c572c47069fb32dce28f4a264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_196d0ef9358e4ccfbdb8317d640df39e",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93c5e0c52d3d4f95bd431cbb48cfaabc",
            "value": 456318
          }
        },
        "bb5a340a49be491590f29cd2e9b91d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df7c33a98d304c5e92475f14f92219ec",
            "placeholder": "​",
            "style": "IPY_MODEL_2981a615eecb418ba51d354a0e2d76f0",
            "value": " 456k/456k [00:00&lt;00:00, 2.76MB/s]"
          }
        },
        "cff28fd85c7b425ca34614c6c4c77598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff03b6bc7774baa8236af7d5f75440f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb19b734194648cfb234c180a0276762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "196d0ef9358e4ccfbdb8317d640df39e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93c5e0c52d3d4f95bd431cbb48cfaabc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df7c33a98d304c5e92475f14f92219ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2981a615eecb418ba51d354a0e2d76f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c767bf66ca5141a39eae62cd062fa789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e59f78ee6e943508f898ed34bfb7806",
              "IPY_MODEL_9cc45dd0e16e43a397351bae524ba7be",
              "IPY_MODEL_343e24f62b5e48dd9e36b23d7defee66"
            ],
            "layout": "IPY_MODEL_0a37ffc1980141cc97e8001f7839e001"
          }
        },
        "5e59f78ee6e943508f898ed34bfb7806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a40fe6c03319484aa00beb04f10d6bb3",
            "placeholder": "​",
            "style": "IPY_MODEL_c54a9116b9d64d4e9837c4098176bc90",
            "value": "tokenizer.json: 100%"
          }
        },
        "9cc45dd0e16e43a397351bae524ba7be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fd449d7f3be4d21bc6ade3269ead3a1",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_678e33184d684179a0bbf23cb52b8d5e",
            "value": 1355256
          }
        },
        "343e24f62b5e48dd9e36b23d7defee66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6a611a0a1f74f64b573ff119bd99e88",
            "placeholder": "​",
            "style": "IPY_MODEL_a86ad591a963427faf1ef59eaa492611",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 4.07MB/s]"
          }
        },
        "0a37ffc1980141cc97e8001f7839e001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a40fe6c03319484aa00beb04f10d6bb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c54a9116b9d64d4e9837c4098176bc90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fd449d7f3be4d21bc6ade3269ead3a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "678e33184d684179a0bbf23cb52b8d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6a611a0a1f74f64b573ff119bd99e88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a86ad591a963427faf1ef59eaa492611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75208a9b43fc4d37820ab7a9e60d4016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f25bb3b296de493097741bfd3efdd4f4",
              "IPY_MODEL_b55938f85384471dafc4920db47e252c",
              "IPY_MODEL_a53451f9ef2c414a944d7c846dd28c22"
            ],
            "layout": "IPY_MODEL_bca411154f154b6ca53ef03a5b82f75e"
          }
        },
        "f25bb3b296de493097741bfd3efdd4f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_321de99d4fd541a690d9722c97a7b3c9",
            "placeholder": "​",
            "style": "IPY_MODEL_09ac27cc56514196a5cfcded4a53412f",
            "value": "config.json: 100%"
          }
        },
        "b55938f85384471dafc4920db47e252c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf19b21461f149b190d61ed75546a71f",
            "max": 762,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ec06dc85dac434c9b4ab9d0554fe1a8",
            "value": 762
          }
        },
        "a53451f9ef2c414a944d7c846dd28c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71336cb6b092480fa058f4150c0c3089",
            "placeholder": "​",
            "style": "IPY_MODEL_e7841249491e4d30bdfb046c9498adbe",
            "value": " 762/762 [00:00&lt;00:00, 39.7kB/s]"
          }
        },
        "bca411154f154b6ca53ef03a5b82f75e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "321de99d4fd541a690d9722c97a7b3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09ac27cc56514196a5cfcded4a53412f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf19b21461f149b190d61ed75546a71f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ec06dc85dac434c9b4ab9d0554fe1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71336cb6b092480fa058f4150c0c3089": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7841249491e4d30bdfb046c9498adbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfe019bb1749462ba38403c6cdac2f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1a7e923e1404571988f1213c95c64e4",
              "IPY_MODEL_c148d437e3874e3396f814fd58787c12",
              "IPY_MODEL_1c2363c423d341ea9844d18c87f85377"
            ],
            "layout": "IPY_MODEL_e36e438e04e3422b8541240b148af727"
          }
        },
        "e1a7e923e1404571988f1213c95c64e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28f9f5083e9846bfa1232e6fedc9a8ea",
            "placeholder": "​",
            "style": "IPY_MODEL_e808c62057a6429eb8a4baade378b36c",
            "value": "model.safetensors: 100%"
          }
        },
        "c148d437e3874e3396f814fd58787c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42fa9d1b3c0f437cadd3596608ac292e",
            "max": 352824413,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ec6f2895f5341f588fe046dd5b1a828",
            "value": 352824413
          }
        },
        "1c2363c423d341ea9844d18c87f85377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ca719d1a09d4b82b3ea9d3b0e9f1357",
            "placeholder": "​",
            "style": "IPY_MODEL_e59dd3cff081464d95391a735964f686",
            "value": " 353M/353M [00:01&lt;00:00, 243MB/s]"
          }
        },
        "e36e438e04e3422b8541240b148af727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28f9f5083e9846bfa1232e6fedc9a8ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e808c62057a6429eb8a4baade378b36c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42fa9d1b3c0f437cadd3596608ac292e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ec6f2895f5341f588fe046dd5b1a828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ca719d1a09d4b82b3ea9d3b0e9f1357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e59dd3cff081464d95391a735964f686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ua0iDXX5sed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655,
          "referenced_widgets": [
            "1984b6bcd45e4f1e897cd28a598f40ef",
            "90b9a960950a4ef8a26a79a291f9549e",
            "0d258d6f23194fc69b42ca1ceb954120",
            "3f8fbd831c0f45cea8494a1878100c38",
            "19dfb48eb79f40e6a130fe6537209110",
            "dffa9442f3124d3dafdc8428d41d14c2",
            "2c67947a2ae54beeb530e4cd251f654d",
            "5b5ec33d10ad4a6688d9a88776926b44",
            "80faeecb00204042b9cf7e1f98be6e17",
            "3fafbe524d924c8384995c9c65da92ba",
            "9a2812663fb34cbfb48302e577c11ce0",
            "bd030dd1a489475685f6f4de38097099",
            "206314163af3424d9af43e0633eb0002",
            "b4702bdce56f419188224e478f6e2cb1",
            "ea58a7323d094d97ad875c39f6b88b8f",
            "8c82823903d142f88e559e1a3806c565",
            "658969ba784f445f95a546aed01ffe6c",
            "379518442f26437ca9681b1793cc52dd",
            "fe00587bd0d84083970f1a05a48af5f8",
            "7358673defd243bf92aa7c27edc6e737",
            "77b133b698a342d7ae1f2d7cb1bc165c",
            "17421287133b436b8a66fb1581ebd177",
            "7e51698dbf1a44a88d949ef284348f19",
            "7be8de019ae34c46beaa1d57532c819f",
            "b1faed6c572c47069fb32dce28f4a264",
            "bb5a340a49be491590f29cd2e9b91d68",
            "cff28fd85c7b425ca34614c6c4c77598",
            "6ff03b6bc7774baa8236af7d5f75440f",
            "fb19b734194648cfb234c180a0276762",
            "196d0ef9358e4ccfbdb8317d640df39e",
            "93c5e0c52d3d4f95bd431cbb48cfaabc",
            "df7c33a98d304c5e92475f14f92219ec",
            "2981a615eecb418ba51d354a0e2d76f0",
            "c767bf66ca5141a39eae62cd062fa789",
            "5e59f78ee6e943508f898ed34bfb7806",
            "9cc45dd0e16e43a397351bae524ba7be",
            "343e24f62b5e48dd9e36b23d7defee66",
            "0a37ffc1980141cc97e8001f7839e001",
            "a40fe6c03319484aa00beb04f10d6bb3",
            "c54a9116b9d64d4e9837c4098176bc90",
            "8fd449d7f3be4d21bc6ade3269ead3a1",
            "678e33184d684179a0bbf23cb52b8d5e",
            "d6a611a0a1f74f64b573ff119bd99e88",
            "a86ad591a963427faf1ef59eaa492611",
            "75208a9b43fc4d37820ab7a9e60d4016",
            "f25bb3b296de493097741bfd3efdd4f4",
            "b55938f85384471dafc4920db47e252c",
            "a53451f9ef2c414a944d7c846dd28c22",
            "bca411154f154b6ca53ef03a5b82f75e",
            "321de99d4fd541a690d9722c97a7b3c9",
            "09ac27cc56514196a5cfcded4a53412f",
            "bf19b21461f149b190d61ed75546a71f",
            "5ec06dc85dac434c9b4ab9d0554fe1a8",
            "71336cb6b092480fa058f4150c0c3089",
            "e7841249491e4d30bdfb046c9498adbe",
            "cfe019bb1749462ba38403c6cdac2f70",
            "e1a7e923e1404571988f1213c95c64e4",
            "c148d437e3874e3396f814fd58787c12",
            "1c2363c423d341ea9844d18c87f85377",
            "e36e438e04e3422b8541240b148af727",
            "28f9f5083e9846bfa1232e6fedc9a8ea",
            "e808c62057a6429eb8a4baade378b36c",
            "42fa9d1b3c0f437cadd3596608ac292e",
            "6ec6f2895f5341f588fe046dd5b1a828",
            "9ca719d1a09d4b82b3ea9d3b0e9f1357",
            "e59dd3cff081464d95391a735964f686"
          ]
        },
        "outputId": "a70e181c-a9b1-4161-f9e9-bfae052725df"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1984b6bcd45e4f1e897cd28a598f40ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd030dd1a489475685f6f4de38097099",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e51698dbf1a44a88d949ef284348f19",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c767bf66ca5141a39eae62cd062fa789",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75208a9b43fc4d37820ab7a9e60d4016",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfe019bb1749462ba38403c6cdac2f70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting GPT-2 text embeddings...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1cfed36046ff>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting GPT-2 text embeddings...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mtext_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gpt2_embeddings_in_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpt2_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-1cfed36046ff>\u001b[0m in \u001b[0;36mget_gpt2_embeddings_in_batches\u001b[0;34m(texts, model, tokenizer, batch_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Use the first token's hidden state as the sentence representation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 )\n\u001b[1;32m    921\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         attn_outputs = self.attn(\n\u001b[0m\u001b[1;32m    405\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mshape_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import gc\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "\n",
        "def load_and_clean_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    # Remove 'Combined_clean' (text) and 'IVFLUIDS' (target) from structured features.\n",
        "    structured_cols = [col for col in df.columns if col not in ['Combined_clean', 'IVFLUIDS']]\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    df[structured_cols] = imputer.fit_transform(df[structured_cols])\n",
        "    df['ID'] = np.arange(len(df))\n",
        "    return df, structured_cols\n",
        "\n",
        "def tokenize_texts(texts, tokenizer, max_length=128):\n",
        "    return tokenizer(texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt')\n",
        "\n",
        "def get_gpt2_embeddings_in_batches(texts, model, tokenizer, batch_size=16):\n",
        "    embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        tokenized = tokenize_texts(batch_texts, tokenizer)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**tokenized)\n",
        "        # Use the first token's hidden state as the sentence representation.\n",
        "        embeddings.append(outputs.last_hidden_state[:, 0, :].cpu().numpy())\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "# Load data from CSV.\n",
        "file_path = '.../cleaned_ed_data.csv'\n",
        "df, structured_cols = load_and_clean_data(file_path)\n",
        "\n",
        "# Process structured data.\n",
        "structured_data = df[structured_cols].values\n",
        "scaler = StandardScaler()\n",
        "structured_data_normalized = scaler.fit_transform(structured_data)\n",
        "\n",
        "# Process text data and target labels.\n",
        "text_data = df['Combined_clean'].tolist()\n",
        "target = df['IVFLUIDS']  # Assume binary target (0 or 1)\n",
        "\n",
        "# Initialize GPT-2 tokenizer and model (using distilgpt2 for efficiency).\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "gpt2_model = GPT2Model.from_pretrained('distilgpt2')\n",
        "gpt2_model.eval()\n",
        "\n",
        "print(\"Extracting GPT-2 text embeddings...\")\n",
        "text_embeddings = get_gpt2_embeddings_in_batches(text_data, gpt2_model, tokenizer, batch_size=50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "data_to_save = {\n",
        "    'structured_data': structured_data_normalized,\n",
        "    'text_embeddings': text_embeddings,\n",
        "    'target': target.values\n",
        "}\n",
        "\n",
        "output_path = '.../model_input_data.pkl'\n",
        "with open(output_path, 'wb') as f:\n",
        "    pickle.dump(data_to_save, f)\n",
        "\n",
        "print(f\"Saved processed data to: {output_path}\")"
      ],
      "metadata": {
        "id": "GKzH94EqXkAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CountVectorizer"
      ],
      "metadata": {
        "id": "RfkWCTIfZ8Dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "import gc\n",
        "\n",
        "def load_and_clean_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    # Remove 'Combined_clean' (text) and 'IVFLUIDS' (target) from structured features.\n",
        "    structured_cols = [col for col in df.columns if col not in ['Combined_clean', 'IVFLUIDS']]\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    df[structured_cols] = imputer.fit_transform(df[structured_cols])\n",
        "    df['ID'] = np.arange(len(df))\n",
        "    return df, structured_cols\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Basic text preprocessing for medical text\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    # Convert to lowercase and remove special characters but keep medical terms\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', str(text).lower())\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "def extract_bow_features(texts, max_features=1000, ngram_range=(1, 2), min_df=2, max_df=0.95):\n",
        "    \"\"\"\n",
        "    Extract Bag of Words features using CountVectorizer\n",
        "\n",
        "    Parameters:\n",
        "    - max_features: Maximum number of features to keep\n",
        "    - ngram_range: Range of n-grams to consider (1,1) for unigrams, (1,2) for unigrams+bigrams\n",
        "    - min_df: Ignore terms that appear in fewer than min_df documents\n",
        "    - max_df: Ignore terms that appear in more than max_df proportion of documents\n",
        "    \"\"\"\n",
        "    print(\"Preprocessing text data...\")\n",
        "    # Preprocess texts\n",
        "    processed_texts = [preprocess_text(text) for text in texts]\n",
        "\n",
        "    print(f\"Extracting BOW features with CountVectorizer...\")\n",
        "    print(f\"Parameters: max_features={max_features}, ngram_range={ngram_range}\")\n",
        "\n",
        "    # Initialize CountVectorizer\n",
        "    vectorizer = CountVectorizer(\n",
        "        max_features=max_features,\n",
        "        ngram_range=ngram_range,\n",
        "        stop_words='english',\n",
        "        min_df=min_df,\n",
        "        max_df=max_df,\n",
        "        lowercase=True,\n",
        "        token_pattern=r'\\b[a-zA-Z]{2,}\\b'  # Only words with 2+ letters\n",
        "    )\n",
        "\n",
        "    # Fit and transform\n",
        "    bow_matrix = vectorizer.fit_transform(processed_texts)\n",
        "    bow_features = bow_matrix.toarray()\n",
        "\n",
        "    # Get feature names for interpretability\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    print(f\"BOW feature matrix shape: {bow_features.shape}\")\n",
        "    print(f\"Vocabulary size: {len(feature_names)}\")\n",
        "    print(f\"Most common features: {feature_names[:10].tolist()}\")\n",
        "\n",
        "    # Memory cleanup\n",
        "    del bow_matrix\n",
        "    gc.collect()\n",
        "\n",
        "    return bow_features, vectorizer, feature_names\n",
        "\n",
        "# Load data from CSV\n",
        "file_path = 'cleaned_ed_data.csv'  # Update your path here\n",
        "df, structured_cols = load_and_clean_data(file_path)\n",
        "\n",
        "# Process structured data\n",
        "structured_data = df[structured_cols].values\n",
        "scaler = StandardScaler()\n",
        "structured_data_normalized = scaler.fit_transform(structured_data)\n",
        "\n",
        "# Process text data and target labels\n",
        "text_data = df['Combined_clean'].tolist()\n",
        "target = df['IVFLUIDS']  # Assume binary target (0 or 1)\n",
        "\n",
        "print(\"Extracting CountVectorizer text features...\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Number of text samples: {len(text_data)}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Extract BOW features - you can adjust these parameters based on your needs\n",
        "text_embeddings, bow_vectorizer, feature_names = extract_bow_features(\n",
        "    text_data,\n",
        "    max_features=500,    # Adjust based on your needs (500-2000 is common)\n",
        "    ngram_range=(1, 2),  # Include both unigrams and bigrams\n",
        "    min_df=2,           # Must appear in at least 2 documents\n",
        "    max_df=0.95         # Must appear in less than 95% of documents\n",
        ")\n",
        "\n",
        "print(f\"Final text embeddings shape: {text_embeddings.shape}\")\n",
        "print(f\"Structured data shape: {structured_data_normalized.shape}\")\n",
        "\n",
        "# Combine structured and text features\n",
        "combined_features = np.hstack([structured_data_normalized, text_embeddings])\n",
        "print(f\"Combined feature matrix shape: {combined_features.shape}\")\n",
        "\n",
        "print(\"\\nCountVectorizer feature extraction complete!\")\n",
        "print(\"Ready for model training...\")\n",
        "\n",
        "# Optional: Show most important features by frequency\n",
        "print(f\"\\nTop 10 most frequent terms:\")\n",
        "feature_sums = np.sum(text_embeddings, axis=0)\n",
        "top_indices = np.argsort(feature_sums)[-10:][::-1]\n",
        "for i, idx in enumerate(top_indices):\n",
        "    print(f\"{i+1}. {feature_names[idx]}: {feature_sums[idx]:.0f} occurrences\")\n",
        "\n",
        "# Save processed data using pickle\n",
        "import pickle\n",
        "\n",
        "data_to_save = {\n",
        "    'structured_data': structured_data_normalized,\n",
        "    'text_embeddings': text_embeddings,\n",
        "    'target': target.values,\n",
        "    'bow_vectorizer': bow_vectorizer,\n",
        "    'scaler': scaler,\n",
        "    'feature_names': feature_names,\n",
        "    'structured_cols': structured_cols\n",
        "}\n",
        "\n",
        "output_path = 'countvectorizer_model_input_data.pkl'\n",
        "with open(output_path, 'wb') as f:\n",
        "    pickle.dump(data_to_save, f)\n",
        "\n",
        "print(f\"\\nSaved CountVectorizer processed data to: {output_path}\")\n",
        "print(\"Saved components:\")\n",
        "print(\"- structured_data: Normalized structured features\")\n",
        "print(\"- text_embeddings: CountVectorizer BOW features\")\n",
        "print(\"- target: Target variable\")\n",
        "print(\"- bow_vectorizer: Fitted CountVectorizer model\")\n",
        "print(\"- scaler: Fitted StandardScaler\")\n",
        "print(\"- feature_names: BOW feature names\")\n",
        "print(\"- structured_cols: Original structured column names\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMbIhCBfadYP",
        "outputId": "f377f488-78d3-48df-f749-7d96067c829d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting CountVectorizer text features...\n",
            "Dataset shape: (13115, 44)\n",
            "Number of text samples: 13115\n",
            "--------------------------------------------------\n",
            "Preprocessing text data...\n",
            "Extracting BOW features with CountVectorizer...\n",
            "Parameters: max_features=500, ngram_range=(1, 2)\n",
            "BOW feature matrix shape: (13115, 500)\n",
            "Vocabulary size: 500\n",
            "Most common features: ['abdominal', 'abdominal pain', 'abnormal', 'abnormal drug', 'abnormal pigmentation', 'abnormal pulsations', 'abnormal sensation', 'abnormalities', 'abuse', 'accident']\n",
            "Final text embeddings shape: (13115, 500)\n",
            "Structured data shape: (13115, 41)\n",
            "Combined feature matrix shape: (13115, 541)\n",
            "\n",
            "CountVectorizer feature extraction complete!\n",
            "Ready for model training...\n",
            "\n",
            "Top 10 most frequent terms:\n",
            "1. pain: 8691 occurrences\n",
            "2. soreness: 3277 occurrences\n",
            "3. ache: 3034 occurrences\n",
            "4. pain ache: 3034 occurrences\n",
            "5. ache soreness: 2965 occurrences\n",
            "6. nos: 2531 occurrences\n",
            "7. unspecified: 2521 occurrences\n",
            "8. discomfort: 2247 occurrences\n",
            "9. soreness discomfort: 2092 occurrences\n",
            "10. abdominal: 1852 occurrences\n",
            "\n",
            "Saved CountVectorizer processed data to: countvectorizer_model_input_data.pkl\n",
            "Saved components:\n",
            "- structured_data: Normalized structured features\n",
            "- text_embeddings: CountVectorizer BOW features\n",
            "- target: Target variable\n",
            "- bow_vectorizer: Fitted CountVectorizer model\n",
            "- scaler: Fitted StandardScaler\n",
            "- feature_names: BOW feature names\n",
            "- structured_cols: Original structured column names\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec"
      ],
      "metadata": {
        "id": "03HuX5dLaiI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "_-I-ApcoavYl",
        "outputId": "010a8b0c-f64b-425c-9b98-4a89ad1c1f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
            "Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.1\n",
            "    Uninstalling scipy-1.16.1:\n",
            "      Successfully uninstalled scipy-1.16.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "3368e41e46db42079671e24d462d229b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "import re\n",
        "import gc\n",
        "import multiprocessing\n",
        "\n",
        "def load_and_clean_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    # Remove 'Combined_clean' (text) and 'IVFLUIDS' (target) from structured features.\n",
        "    structured_cols = [col for col in df.columns if col not in ['Combined_clean', 'IVFLUIDS']]\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    df[structured_cols] = imputer.fit_transform(df[structured_cols])\n",
        "    df['ID'] = np.arange(len(df))\n",
        "    return df, structured_cols\n",
        "\n",
        "def preprocess_text_for_w2v(text):\n",
        "    \"\"\"Text preprocessing optimized for Word2Vec\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    # Convert to lowercase and remove special characters\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', str(text).lower())\n",
        "    # Remove numbers (optional - you might want to keep medical codes/values)\n",
        "    # text = re.sub(r'\\d+', '', text)\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "def extract_word2vec_features(texts, vector_size=100, window=5, min_count=2,\n",
        "                             epochs=10, sg=0, negative=5):\n",
        "    \"\"\"\n",
        "    Extract Word2Vec features by training model and averaging word embeddings\n",
        "\n",
        "    Parameters:\n",
        "    - vector_size: Dimensionality of the word vectors (100-300 is common)\n",
        "    - window: Maximum distance between current and predicted word\n",
        "    - min_count: Ignores words that appear fewer than this many times\n",
        "    - epochs: Number of training epochs\n",
        "    - sg: Training algorithm (0=CBOW, 1=Skip-gram)\n",
        "    - negative: Number of negative samples for negative sampling\n",
        "    \"\"\"\n",
        "    print(\"Preprocessing text data for Word2Vec...\")\n",
        "\n",
        "    # Preprocess texts\n",
        "    processed_texts = [preprocess_text_for_w2v(text) for text in texts]\n",
        "\n",
        "    # Tokenize using gensim's simple_preprocess (removes punctuation, converts to lowercase)\n",
        "    tokenized_texts = [simple_preprocess(text, deacc=True, min_len=2, max_len=50)\n",
        "                      for text in processed_texts]\n",
        "\n",
        "    # Remove empty documents\n",
        "    tokenized_texts = [tokens for tokens in tokenized_texts if len(tokens) > 0]\n",
        "\n",
        "    print(f\"Training Word2Vec model...\")\n",
        "    print(f\"Parameters: vector_size={vector_size}, window={window}, min_count={min_count}\")\n",
        "    print(f\"Number of documents: {len(tokenized_texts)}\")\n",
        "\n",
        "    # Calculate total vocabulary for info\n",
        "    all_words = [word for tokens in tokenized_texts for word in tokens]\n",
        "    unique_words = len(set(all_words))\n",
        "    print(f\"Total unique words before filtering: {unique_words}\")\n",
        "\n",
        "    # Train Word2Vec model\n",
        "    cores = multiprocessing.cpu_count()\n",
        "    w2v_model = Word2Vec(\n",
        "        sentences=tokenized_texts,\n",
        "        vector_size=vector_size,\n",
        "        window=window,\n",
        "        min_count=min_count,\n",
        "        workers=cores,\n",
        "        sg=sg,  # 0 = CBOW, 1 = Skip-gram\n",
        "        epochs=epochs,\n",
        "        negative=negative,\n",
        "        seed=42,\n",
        "        compute_loss=True\n",
        "    )\n",
        "\n",
        "    print(f\"Vocabulary size after filtering: {len(w2v_model.wv.key_to_index)}\")\n",
        "    print(f\"Training loss: {w2v_model.get_latest_training_loss():.2f}\")\n",
        "\n",
        "    # Function to get document vector by averaging word vectors\n",
        "    def get_document_vector(tokens, model, vector_size):\n",
        "        \"\"\"Average word vectors for all words in document\"\"\"\n",
        "        vectors = []\n",
        "        for token in tokens:\n",
        "            if token in model.wv:\n",
        "                vectors.append(model.wv[token])\n",
        "\n",
        "        if vectors:\n",
        "            # Average all word vectors in the document\n",
        "            return np.mean(vectors, axis=0)\n",
        "        else:\n",
        "            # Return zero vector if no words found in vocabulary\n",
        "            return np.zeros(vector_size)\n",
        "\n",
        "    print(\"Generating document embeddings...\")\n",
        "\n",
        "    # Create document embeddings for all original texts (including empty ones)\n",
        "    w2v_features = []\n",
        "    for i, text in enumerate(processed_texts):\n",
        "        if i < len(tokenized_texts):\n",
        "            # Find corresponding tokenized text\n",
        "            tokens = simple_preprocess(text, deacc=True, min_len=2, max_len=50)\n",
        "            doc_vector = get_document_vector(tokens, w2v_model, vector_size)\n",
        "        else:\n",
        "            # Handle empty documents\n",
        "            doc_vector = np.zeros(vector_size)\n",
        "\n",
        "        w2v_features.append(doc_vector)\n",
        "\n",
        "    w2v_features = np.array(w2v_features)\n",
        "\n",
        "    print(f\"Word2Vec feature matrix shape: {w2v_features.shape}\")\n",
        "\n",
        "    # Show some model statistics\n",
        "    if len(w2v_model.wv.key_to_index) > 0:\n",
        "        # Most similar words to common medical terms (if they exist in vocabulary)\n",
        "        test_words = ['patient', 'pain', 'blood', 'treatment', 'hospital', 'diagnosis']\n",
        "        print(f\"\\nSample word similarities:\")\n",
        "        for word in test_words:\n",
        "            if word in w2v_model.wv:\n",
        "                try:\n",
        "                    similar = w2v_model.wv.most_similar(word, topn=3)\n",
        "                    print(f\"Words similar to '{word}': {[w for w, s in similar]}\")\n",
        "                except:\n",
        "                    pass\n",
        "                break  # Just show one example\n",
        "\n",
        "    # Memory cleanup\n",
        "    gc.collect()\n",
        "\n",
        "    return w2v_features, w2v_model\n",
        "\n",
        "# Load data from CSV\n",
        "file_path = 'cleaned_ed_data.csv'  # Update your path here\n",
        "df, structured_cols = load_and_clean_data(file_path)\n",
        "\n",
        "# Process structured data\n",
        "structured_data = df[structured_cols].values\n",
        "scaler = StandardScaler()\n",
        "structured_data_normalized = scaler.fit_transform(structured_data)\n",
        "\n",
        "# Process text data and target labels\n",
        "text_data = df['Combined_clean'].tolist()\n",
        "target = df['IVFLUIDS']  # Assume binary target (0 or 1)\n",
        "\n",
        "print(\"Extracting Word2Vec text features...\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Number of text samples: {len(text_data)}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Extract Word2Vec features - you can adjust these parameters\n",
        "text_embeddings, w2v_model = extract_word2vec_features(\n",
        "    text_data,\n",
        "    vector_size=100,    # Dimensionality (50-300 common, 100 is good balance)\n",
        "    window=5,          # Context window size\n",
        "    min_count=2,       # Minimum word frequency\n",
        "    epochs=10,         # Training epochs (more = better quality but slower)\n",
        "    sg=0,             # 0=CBOW (faster), 1=Skip-gram (better for rare words)\n",
        "    negative=5        # Negative sampling parameter\n",
        ")\n",
        "\n",
        "print(f\"Final text embeddings shape: {text_embeddings.shape}\")\n",
        "print(f\"Structured data shape: {structured_data_normalized.shape}\")\n",
        "\n",
        "# Combine structured and text features\n",
        "combined_features = np.hstack([structured_data_normalized, text_embeddings])\n",
        "print(f\"Combined feature matrix shape: {combined_features.shape}\")\n",
        "\n",
        "print(\"\\nWord2Vec feature extraction complete!\")\n",
        "print(\"Ready for model training...\")\n",
        "\n",
        "# Optional: Save the trained Word2Vec model for future use\n",
        "# w2v_model.save(\"medical_word2vec_model.bin\")\n",
        "# print(\"Word2Vec model saved!\")\n",
        "\n",
        "# Optional: Analyze embedding quality\n",
        "print(f\"\\nEmbedding statistics:\")\n",
        "print(f\"Mean embedding magnitude: {np.mean(np.linalg.norm(text_embeddings, axis=1)):.3f}\")\n",
        "print(f\"Std embedding magnitude: {np.std(np.linalg.norm(text_embeddings, axis=1)):.3f}\")\n",
        "print(f\"Zero embeddings (empty docs): {np.sum(np.all(text_embeddings == 0, axis=1))}\")\n",
        "\n",
        "# Save processed data using pickle\n",
        "import pickle\n",
        "\n",
        "data_to_save = {\n",
        "    'structured_data': structured_data_normalized,\n",
        "    'text_embeddings': text_embeddings,\n",
        "    'target': target.values,\n",
        "    'w2v_model': w2v_model,\n",
        "    'scaler': scaler,\n",
        "    'structured_cols': structured_cols\n",
        "}\n",
        "\n",
        "output_path = 'word2vec_model_input_data.pkl'\n",
        "with open(output_path, 'wb') as f:\n",
        "    pickle.dump(data_to_save, f)\n",
        "\n",
        "print(f\"\\nSaved Word2Vec processed data to: {output_path}\")\n",
        "print(\"Saved components:\")\n",
        "print(\"- structured_data: Normalized structured features\")\n",
        "print(\"- text_embeddings: Word2Vec document embeddings\")\n",
        "print(\"- target: Target variable\")\n",
        "print(\"- w2v_model: Trained Word2Vec model\")\n",
        "print(\"- scaler: Fitted StandardScaler\")\n",
        "print(\"- structured_cols: Original structured column names\")\n",
        "\n",
        "# Alternative: Save Word2Vec model separately for reuse\n",
        "w2v_model.save(\"medical_word2vec_model.bin\")\n",
        "print(f\"\\nAlso saved Word2Vec model separately to: medical_word2vec_model.bin\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PweZE5tNakvW",
        "outputId": "8c330226-f0de-488f-d06e-c890af6b0a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Word2Vec text features...\n",
            "Dataset shape: (13115, 44)\n",
            "Number of text samples: 13115\n",
            "--------------------------------------------------\n",
            "Preprocessing text data for Word2Vec...\n",
            "Training Word2Vec model...\n",
            "Parameters: vector_size=100, window=5, min_count=2\n",
            "Number of documents: 13104\n",
            "Total unique words before filtering: 1096\n",
            "Vocabulary size after filtering: 955\n",
            "Training loss: 558055.69\n",
            "Generating document embeddings...\n",
            "Word2Vec feature matrix shape: (13115, 100)\n",
            "\n",
            "Sample word similarities:\n",
            "Words similar to 'patient': ['spokesperson', 'refused', 'care']\n",
            "Final text embeddings shape: (13115, 100)\n",
            "Structured data shape: (13115, 41)\n",
            "Combined feature matrix shape: (13115, 141)\n",
            "\n",
            "Word2Vec feature extraction complete!\n",
            "Ready for model training...\n",
            "\n",
            "Embedding statistics:\n",
            "Mean embedding magnitude: 4.456\n",
            "Std embedding magnitude: 1.014\n",
            "Zero embeddings (empty docs): 22\n",
            "\n",
            "Saved Word2Vec processed data to: word2vec_model_input_data.pkl\n",
            "Saved components:\n",
            "- structured_data: Normalized structured features\n",
            "- text_embeddings: Word2Vec document embeddings\n",
            "- target: Target variable\n",
            "- w2v_model: Trained Word2Vec model\n",
            "- scaler: Fitted StandardScaler\n",
            "- structured_cols: Original structured column names\n",
            "\n",
            "Also saved Word2Vec model separately to: medical_word2vec_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def save_data_robust(data_dict, output_path, backup=True):\n",
        "    \"\"\"\n",
        "    Robust data saving with error checking and backup\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create backup if file exists\n",
        "        if backup and os.path.exists(output_path):\n",
        "            backup_path = output_path.replace('.pkl', '_backup.pkl')\n",
        "            if os.path.exists(backup_path):\n",
        "                os.remove(backup_path)\n",
        "            os.rename(output_path, backup_path)\n",
        "            print(f\"Created backup: {backup_path}\")\n",
        "\n",
        "        # Save with explicit protocol and error checking\n",
        "        print(f\"Saving data to: {output_path}\")\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(data_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "        # Verify the file was saved correctly\n",
        "        file_size = os.path.getsize(output_path)\n",
        "        print(f\"File saved successfully. Size: {file_size / (1024*1024):.2f} MB\")\n",
        "\n",
        "        # Test loading to verify integrity\n",
        "        print(\"Verifying file integrity...\")\n",
        "        with open(output_path, 'rb') as f:\n",
        "            test_load = pickle.load(f)\n",
        "\n",
        "        print(\"✓ File verification successful!\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving data: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def load_data_robust(file_path):\n",
        "    \"\"\"\n",
        "    Robust data loading with error handling\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"File not found: {file_path}\")\n",
        "            return None\n",
        "\n",
        "        file_size = os.path.getsize(file_path)\n",
        "        print(f\"Loading file: {file_path} (Size: {file_size / (1024*1024):.2f} MB)\")\n",
        "\n",
        "        with open(file_path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "\n",
        "        print(\"✓ Data loaded successfully!\")\n",
        "        print(f\"Keys in loaded data: {list(data.keys())}\")\n",
        "\n",
        "        return data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {str(e)}\")\n",
        "\n",
        "        # Try backup file if it exists\n",
        "        backup_path = file_path.replace('.pkl', '_backup.pkl')\n",
        "        if os.path.exists(backup_path):\n",
        "            print(f\"Trying backup file: {backup_path}\")\n",
        "            try:\n",
        "                with open(backup_path, 'rb') as f:\n",
        "                    data = pickle.load(f)\n",
        "                print(\"✓ Backup file loaded successfully!\")\n",
        "                return data\n",
        "            except Exception as e2:\n",
        "                print(f\"Backup file also corrupted: {str(e2)}\")\n",
        "\n",
        "        return None\n",
        "\n",
        "# For CountVectorizer implementation\n",
        "def save_countvectorizer_data(structured_data_normalized, text_embeddings, target,\n",
        "                             bow_vectorizer, scaler, feature_names, structured_cols):\n",
        "    \"\"\"Save CountVectorizer processed data\"\"\"\n",
        "\n",
        "    data_to_save = {\n",
        "        'structured_data': structured_data_normalized,\n",
        "        'text_embeddings': text_embeddings,\n",
        "        'target': target.values if hasattr(target, 'values') else target,\n",
        "        'bow_vectorizer': bow_vectorizer,\n",
        "        'scaler': scaler,\n",
        "        'feature_names': feature_names,\n",
        "        'structured_cols': structured_cols,\n",
        "        'metadata': {\n",
        "            'structured_shape': structured_data_normalized.shape,\n",
        "            'text_shape': text_embeddings.shape,\n",
        "            'n_samples': len(target),\n",
        "            'vocab_size': len(feature_names)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    output_path = 'countvectorizer_model_input_data.pkl'\n",
        "    success = save_data_robust(data_to_save, output_path)\n",
        "\n",
        "    if success:\n",
        "        print(\"\\n✓ CountVectorizer data saved successfully!\")\n",
        "        print(\"Saved components:\")\n",
        "        print(f\"- structured_data: {data_to_save['metadata']['structured_shape']}\")\n",
        "        print(f\"- text_embeddings: {data_to_save['metadata']['text_shape']}\")\n",
        "        print(f\"- target: {data_to_save['metadata']['n_samples']} samples\")\n",
        "        print(f\"- vocabulary: {data_to_save['metadata']['vocab_size']} features\")\n",
        "\n",
        "    return success\n",
        "\n",
        "# For Word2Vec implementation\n",
        "def save_word2vec_data(structured_data_normalized, text_embeddings, target,\n",
        "                      w2v_model, scaler, structured_cols):\n",
        "    \"\"\"Save Word2Vec processed data\"\"\"\n",
        "\n",
        "    data_to_save = {\n",
        "        'structured_data': structured_data_normalized,\n",
        "        'text_embeddings': text_embeddings,\n",
        "        'target': target.values if hasattr(target, 'values') else target,\n",
        "        'w2v_model': w2v_model,\n",
        "        'scaler': scaler,\n",
        "        'structured_cols': structured_cols,\n",
        "        'metadata': {\n",
        "            'structured_shape': structured_data_normalized.shape,\n",
        "            'text_shape': text_embeddings.shape,\n",
        "            'n_samples': len(target),\n",
        "            'vector_size': text_embeddings.shape[1],\n",
        "            'vocab_size': len(w2v_model.wv.key_to_index)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    output_path = 'word2vec_model_input_data.pkl'\n",
        "    success = save_data_robust(data_to_save, output_path)\n",
        "\n",
        "    if success:\n",
        "        print(\"\\n✓ Word2Vec data saved successfully!\")\n",
        "        print(\"Saved components:\")\n",
        "        print(f\"- structured_data: {data_to_save['metadata']['structured_shape']}\")\n",
        "        print(f\"- text_embeddings: {data_to_save['metadata']['text_shape']}\")\n",
        "        print(f\"- target: {data_to_save['metadata']['n_samples']} samples\")\n",
        "        print(f\"- w2v vocabulary: {data_to_save['metadata']['vocab_size']} words\")\n",
        "\n",
        "        # Also save Word2Vec model separately\n",
        "        try:\n",
        "            w2v_model.save(\"medical_word2vec_model.bin\")\n",
        "            print(\"- w2v_model: Also saved separately as medical_word2vec_model.bin\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not save separate W2V model: {e}\")\n",
        "\n",
        "    return success\n",
        "\n",
        "# Loading functions\n",
        "def load_countvectorizer_data():\n",
        "    \"\"\"Load CountVectorizer processed data\"\"\"\n",
        "    return load_data_robust('countvectorizer_model_input_data.pkl')\n",
        "\n",
        "def load_word2vec_data():\n",
        "    \"\"\"Load Word2Vec processed data\"\"\"\n",
        "    return load_data_robust('word2vec_model_input_data.pkl')\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Example for loading data\n",
        "    print(\"Attempting to load CountVectorizer data...\")\n",
        "    cv_data = load_countvectorizer_data()\n",
        "\n",
        "    if cv_data is not None:\n",
        "        print(\"CountVectorizer data loaded successfully!\")\n",
        "        print(f\"Available keys: {list(cv_data.keys())}\")\n",
        "        if 'metadata' in cv_data:\n",
        "            print(f\"Metadata: {cv_data['metadata']}\")\n",
        "    else:\n",
        "        print(\"Failed to load CountVectorizer data.\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "    print(\"Attempting to load Word2Vec data...\")\n",
        "    w2v_data = load_word2vec_data()\n",
        "\n",
        "    if w2v_data is not None:\n",
        "        print(\"Word2Vec data loaded successfully!\")\n",
        "        print(f\"Available keys: {list(w2v_data.keys())}\")\n",
        "        if 'metadata' in w2v_data:\n",
        "            print(f\"Metadata: {w2v_data['metadata']}\")\n",
        "    else:\n",
        "        print(\"Failed to load Word2Vec data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbau9oj1c54r",
        "outputId": "26c09c0f-7d20-408c-9fec-38261ade1746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load CountVectorizer data...\n",
            "Loading file: countvectorizer_model_input_data.pkl (Size: 54.25 MB)\n",
            "✓ Data loaded successfully!\n",
            "Keys in loaded data: ['structured_data', 'text_embeddings', 'target', 'bow_vectorizer', 'scaler', 'feature_names', 'structured_cols']\n",
            "CountVectorizer data loaded successfully!\n",
            "Available keys: ['structured_data', 'text_embeddings', 'target', 'bow_vectorizer', 'scaler', 'feature_names', 'structured_cols']\n",
            "\n",
            "==================================================\n",
            "Attempting to load Word2Vec data...\n",
            "Loading file: word2vec_model_input_data.pkl (Size: 14.98 MB)\n",
            "✓ Data loaded successfully!\n",
            "Keys in loaded data: ['structured_data', 'text_embeddings', 'target', 'w2v_model', 'scaler', 'structured_cols']\n",
            "Word2Vec data loaded successfully!\n",
            "Available keys: ['structured_data', 'text_embeddings', 'target', 'w2v_model', 'scaler', 'structured_cols']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Solution 1: Check what keys are actually available\n",
        "print(\"Checking available keys in your saved data...\")\n",
        "\n",
        "try:\n",
        "    with open(\"countvectorizer_model_input_data.pkl\", \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    print(\"Available keys:\", list(data.keys()))\n",
        "    print(\"\\nData shapes:\")\n",
        "    for key, value in data.items():\n",
        "        if hasattr(value, 'shape'):\n",
        "            print(f\"- {key}: {value.shape}\")\n",
        "        elif hasattr(value, '__len__'):\n",
        "            print(f\"- {key}: length {len(value)}\")\n",
        "        else:\n",
        "            print(f\"- {key}: {type(value)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file: {e}\")\n",
        "\n",
        "# Solution 2: Load data without IDs (create them manually)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Loading data and creating IDs manually...\")\n",
        "\n",
        "try:\n",
        "    with open(\"countvectorizer_model_input_data.pkl\", \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    structured_data_normalized = data[\"structured_data\"]\n",
        "    text_embeddings = data[\"text_embeddings\"]\n",
        "    target = data[\"target\"]\n",
        "\n",
        "    # Create IDs manually based on the number of samples\n",
        "    n_samples = len(target)\n",
        "    id_array = np.arange(n_samples)\n",
        "\n",
        "    print(\"✓ Data loaded successfully!\")\n",
        "    print(f\"- Structured data shape: {structured_data_normalized.shape}\")\n",
        "    print(f\"- Text embeddings shape: {text_embeddings.shape}\")\n",
        "    print(f\"- Target shape: {target.shape}\")\n",
        "    print(f\"- Created IDs: {id_array.shape} (0 to {n_samples-1})\")\n",
        "\n",
        "    # Optional: Save the data again with IDs included\n",
        "    print(\"\\nAdding IDs to saved data...\")\n",
        "    data[\"ids\"] = id_array\n",
        "\n",
        "    with open(\"countvectorizer_model_input_data.pkl\", \"wb\") as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "    print(\"✓ Updated pickle file with IDs included\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "# Solution 3: Updated saving function that includes IDs\n",
        "def save_countvectorizer_data_with_ids(structured_data_normalized, text_embeddings, target,\n",
        "                                      bow_vectorizer, scaler, feature_names, structured_cols, ids=None):\n",
        "    \"\"\"Save CountVectorizer processed data including IDs\"\"\"\n",
        "\n",
        "    # Create IDs if not provided\n",
        "    if ids is None:\n",
        "        ids = np.arange(len(target))\n",
        "\n",
        "    data_to_save = {\n",
        "        'structured_data': structured_data_normalized,\n",
        "        'text_embeddings': text_embeddings,\n",
        "        'target': target.values if hasattr(target, 'values') else target,\n",
        "        'ids': ids,  # Include IDs\n",
        "        'bow_vectorizer': bow_vectorizer,\n",
        "        'scaler': scaler,\n",
        "        'feature_names': feature_names,\n",
        "        'structured_cols': structured_cols,\n",
        "        'metadata': {\n",
        "            'structured_shape': structured_data_normalized.shape,\n",
        "            'text_shape': text_embeddings.shape,\n",
        "            'n_samples': len(target),\n",
        "            'vocab_size': len(feature_names)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    output_path = 'countvectorizer_model_input_data.pkl'\n",
        "\n",
        "    try:\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(data_to_save, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "        print(f\"✓ Data saved successfully to {output_path}\")\n",
        "        print(\"Saved components:\")\n",
        "        print(f\"- structured_data: {data_to_save['metadata']['structured_shape']}\")\n",
        "        print(f\"- text_embeddings: {data_to_save['metadata']['text_shape']}\")\n",
        "        print(f\"- target: {data_to_save['metadata']['n_samples']} samples\")\n",
        "        print(f\"- ids: {ids.shape}\")\n",
        "        print(f\"- vocabulary: {data_to_save['metadata']['vocab_size']} features\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving data: {e}\")\n",
        "        return False\n",
        "\n",
        "# Solution 4: Load data with proper error handling\n",
        "def load_data_with_ids(file_path):\n",
        "    \"\"\"Load data and ensure IDs are present\"\"\"\n",
        "\n",
        "    try:\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            data = pickle.load(f)\n",
        "\n",
        "        # Check if IDs exist, create if not\n",
        "        if 'ids' not in data:\n",
        "            print(\"Warning: 'ids' not found in saved data. Creating them...\")\n",
        "            n_samples = len(data['target'])\n",
        "            data['ids'] = np.arange(n_samples)\n",
        "            print(f\"Created IDs: 0 to {n_samples-1}\")\n",
        "\n",
        "        return data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example usage:\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Example: Loading data with automatic ID creation\")\n",
        "\n",
        "data = load_data_with_ids(\"countvectorizer_model_input_data.pkl\")\n",
        "\n",
        "if data is not None:\n",
        "    structured_data_normalized = data[\"structured_data\"]\n",
        "    text_embeddings = data[\"text_embeddings\"]\n",
        "    target = data[\"target\"]\n",
        "    id_array = data[\"ids\"]\n",
        "\n",
        "    print(\"✓ All data loaded successfully including IDs!\")\n",
        "    print(f\"ID range: {id_array.min()} to {id_array.max()}\")\n",
        "else:\n",
        "    print(\"Failed to load data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwhHr0kFdNI_",
        "outputId": "907e3566-2461-4214-c472-fea97eca8d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking available keys in your saved data...\n",
            "Available keys: ['structured_data', 'text_embeddings', 'target', 'bow_vectorizer', 'scaler', 'feature_names', 'structured_cols']\n",
            "\n",
            "Data shapes:\n",
            "- structured_data: (13115, 41)\n",
            "- text_embeddings: (13115, 500)\n",
            "- target: (13115,)\n",
            "- bow_vectorizer: <class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
            "- scaler: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
            "- feature_names: (500,)\n",
            "- structured_cols: length 41\n",
            "\n",
            "==================================================\n",
            "Loading data and creating IDs manually...\n",
            "✓ Data loaded successfully!\n",
            "- Structured data shape: (13115, 41)\n",
            "- Text embeddings shape: (13115, 500)\n",
            "- Target shape: (13115,)\n",
            "- Created IDs: (13115,) (0 to 13114)\n",
            "\n",
            "Adding IDs to saved data...\n",
            "✓ Updated pickle file with IDs included\n",
            "\n",
            "==================================================\n",
            "Example: Loading data with automatic ID creation\n",
            "✓ All data loaded successfully including IDs!\n",
            "ID range: 0 to 13114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Solution 1: Check what keys are actually available in Word2Vec data\n",
        "print(\"Checking available keys in Word2Vec saved data...\")\n",
        "\n",
        "try:\n",
        "    with open(\"word2vec_model_input_data.pkl\", \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    print(\"Available keys:\", list(data.keys()))\n",
        "    print(\"\\nData shapes:\")\n",
        "    for key, value in data.items():\n",
        "        if hasattr(value, 'shape'):\n",
        "            print(f\"- {key}: {value.shape}\")\n",
        "        elif hasattr(value, '__len__'):\n",
        "            try:\n",
        "                print(f\"- {key}: length {len(value)}\")\n",
        "            except:\n",
        "                print(f\"- {key}: {type(value)}\")\n",
        "        else:\n",
        "            print(f\"- {key}: {type(value)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading Word2Vec file: {e}\")\n",
        "\n",
        "# Solution 2: Load Word2Vec data without IDs (create them manually)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Loading Word2Vec data and creating IDs manually...\")\n",
        "\n",
        "try:\n",
        "    with open(\"word2vec_model_input_data.pkl\", \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "\n",
        "    structured_data_normalized = data[\"structured_data\"]\n",
        "    text_embeddings = data[\"text_embeddings\"]\n",
        "    target = data[\"target\"]\n",
        "\n",
        "    # Create IDs manually based on the number of samples\n",
        "    n_samples = len(target)\n",
        "    id_array = np.arange(n_samples)\n",
        "\n",
        "    print(\"✓ Word2Vec data loaded successfully!\")\n",
        "    print(f\"- Structured data shape: {structured_data_normalized.shape}\")\n",
        "    print(f\"- Text embeddings shape: {text_embeddings.shape}\")\n",
        "    print(f\"- Target shape: {target.shape}\")\n",
        "    print(f\"- Created IDs: {id_array.shape} (0 to {n_samples-1})\")\n",
        "\n",
        "    # Optional: Save the data again with IDs included\n",
        "    print(\"\\nAdding IDs to Word2Vec saved data...\")\n",
        "    data[\"ids\"] = id_array\n",
        "\n",
        "    with open(\"word2vec_model_input_data.pkl\", \"wb\") as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "    print(\"✓ Updated Word2Vec pickle file with IDs included\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "# Solution 3: Updated Word2Vec saving function that includes IDs\n",
        "def save_word2vec_data_with_ids(structured_data_normalized, text_embeddings, target,\n",
        "                               w2v_model, scaler, structured_cols, ids=None):\n",
        "    \"\"\"Save Word2Vec processed data including IDs\"\"\"\n",
        "\n",
        "    # Create IDs if not provided\n",
        "    if ids is None:\n",
        "        ids = np.arange(len(target))\n",
        "\n",
        "    data_to_save = {\n",
        "        'structured_data': structured_data_normalized,\n",
        "        'text_embeddings': text_embeddings,\n",
        "        'target': target.values if hasattr(target, 'values') else target,\n",
        "        'ids': ids,  # Include IDs\n",
        "        'w2v_model': w2v_model,\n",
        "        'scaler': scaler,\n",
        "        'structured_cols': structured_cols,\n",
        "        'metadata': {\n",
        "            'structured_shape': structured_data_normalized.shape,\n",
        "            'text_shape': text_embeddings.shape,\n",
        "            'n_samples': len(target),\n",
        "            'vector_size': text_embeddings.shape[1],\n",
        "            'vocab_size': len(w2v_model.wv.key_to_index)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    output_path = 'word2vec_model_input_data.pkl'\n",
        "\n",
        "    try:\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(data_to_save, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "        print(f\"✓ Word2Vec data saved successfully to {output_path}\")\n",
        "        print(\"Saved components:\")\n",
        "        print(f\"- structured_data: {data_to_save['metadata']['structured_shape']}\")\n",
        "        print(f\"- text_embeddings: {data_to_save['metadata']['text_shape']}\")\n",
        "        print(f\"- target: {data_to_save['metadata']['n_samples']} samples\")\n",
        "        print(f\"- ids: {ids.shape}\")\n",
        "        print(f\"- w2v vocabulary: {data_to_save['metadata']['vocab_size']} words\")\n",
        "\n",
        "        # Also save Word2Vec model separately\n",
        "        try:\n",
        "            w2v_model.save(\"medical_word2vec_model.bin\")\n",
        "            print(\"- w2v_model: Also saved separately as medical_word2vec_model.bin\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not save separate W2V model: {e}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving Word2Vec data: {e}\")\n",
        "        return False\n",
        "\n",
        "# Solution 4: Load Word2Vec data with proper error handling\n",
        "def load_word2vec_data_with_ids(file_path):\n",
        "    \"\"\"Load Word2Vec data and ensure IDs are present\"\"\"\n",
        "\n",
        "    try:\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            data = pickle.load(f)\n",
        "\n",
        "        # Check if IDs exist, create if not\n",
        "        if 'ids' not in data:\n",
        "            print(\"Warning: 'ids' not found in Word2Vec saved data. Creating them...\")\n",
        "            n_samples = len(data['target'])\n",
        "            data['ids'] = np.arange(n_samples)\n",
        "            print(f\"Created IDs: 0 to {n_samples-1}\")\n",
        "\n",
        "        return data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading Word2Vec data: {e}\")\n",
        "        return None\n",
        "\n",
        "# Solution 5: Universal function for both CountVectorizer and Word2Vec\n",
        "def load_any_model_data_with_ids(file_path):\n",
        "    \"\"\"Universal loader that works for both CountVectorizer and Word2Vec data\"\"\"\n",
        "\n",
        "    try:\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            data = pickle.load(f)\n",
        "\n",
        "        print(f\"✓ Loaded {file_path}\")\n",
        "        print(f\"Available keys: {list(data.keys())}\")\n",
        "\n",
        "        # Check if IDs exist, create if not\n",
        "        if 'ids' not in data:\n",
        "            print(\"Warning: 'ids' not found. Creating them...\")\n",
        "            n_samples = len(data['target'])\n",
        "            data['ids'] = np.arange(n_samples)\n",
        "            print(f\"Created IDs: 0 to {n_samples-1}\")\n",
        "\n",
        "            # Save back with IDs\n",
        "            with open(file_path, \"wb\") as f:\n",
        "                pickle.dump(data, f)\n",
        "            print(f\"✓ Updated {file_path} with IDs\")\n",
        "\n",
        "        return data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example usage for Word2Vec:\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Example: Loading Word2Vec data with automatic ID creation\")\n",
        "\n",
        "w2v_data = load_word2vec_data_with_ids(\"word2vec_model_input_data.pkl\")\n",
        "\n",
        "if w2v_data is not None:\n",
        "    structured_data_normalized = w2v_data[\"structured_data\"]\n",
        "    text_embeddings = w2v_data[\"text_embeddings\"]\n",
        "    target = w2v_data[\"target\"]\n",
        "    id_array = w2v_data[\"ids\"]\n",
        "    w2v_model = w2v_data[\"w2v_model\"]\n",
        "\n",
        "    print(\"✓ All Word2Vec data loaded successfully including IDs!\")\n",
        "    print(f\"ID range: {id_array.min()} to {id_array.max()}\")\n",
        "    print(f\"Word2Vec vocabulary size: {len(w2v_model.wv.key_to_index)}\")\n",
        "else:\n",
        "    print(\"Failed to load Word2Vec data\")\n",
        "\n",
        "# Quick fix for immediate use:\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"QUICK FIX - Use this code directly:\")\n",
        "print(\"\"\"\n",
        "# For Word2Vec data:\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "with open(\"word2vec_model_input_data.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "structured_data_normalized = data[\"structured_data\"]\n",
        "text_embeddings = data[\"text_embeddings\"]\n",
        "target = data[\"target\"]\n",
        "id_array = np.arange(len(target))  # Create IDs manually\n",
        "\n",
        "print(\"✓ Word2Vec data loaded with manually created IDs!\")\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maZCAcyPdchN",
        "outputId": "e902e5e6-ce20-482e-c697-9479f93bbea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking available keys in Word2Vec saved data...\n",
            "Available keys: ['structured_data', 'text_embeddings', 'target', 'w2v_model', 'scaler', 'structured_cols']\n",
            "\n",
            "Data shapes:\n",
            "- structured_data: (13115, 41)\n",
            "- text_embeddings: (13115, 100)\n",
            "- target: (13115,)\n",
            "- w2v_model: <class 'gensim.models.word2vec.Word2Vec'>\n",
            "- scaler: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
            "- structured_cols: length 41\n",
            "\n",
            "==================================================\n",
            "Loading Word2Vec data and creating IDs manually...\n",
            "✓ Word2Vec data loaded successfully!\n",
            "- Structured data shape: (13115, 41)\n",
            "- Text embeddings shape: (13115, 100)\n",
            "- Target shape: (13115,)\n",
            "- Created IDs: (13115,) (0 to 13114)\n",
            "\n",
            "Adding IDs to Word2Vec saved data...\n",
            "✓ Updated Word2Vec pickle file with IDs included\n",
            "\n",
            "==================================================\n",
            "Example: Loading Word2Vec data with automatic ID creation\n",
            "✓ All Word2Vec data loaded successfully including IDs!\n",
            "ID range: 0 to 13114\n",
            "Word2Vec vocabulary size: 955\n",
            "\n",
            "==================================================\n",
            "QUICK FIX - Use this code directly:\n",
            "\n",
            "# For Word2Vec data:\n",
            "import pickle\n",
            "import numpy as np\n",
            "\n",
            "with open(\"word2vec_model_input_data.pkl\", \"rb\") as f:\n",
            "    data = pickle.load(f)\n",
            "\n",
            "structured_data_normalized = data[\"structured_data\"]\n",
            "text_embeddings = data[\"text_embeddings\"]\n",
            "target = data[\"target\"]\n",
            "id_array = np.arange(len(target))  # Create IDs manually\n",
            "\n",
            "print(\"✓ Word2Vec data loaded with manually created IDs!\")\n",
            "\n"
          ]
        }
      ]
    }
  ]
}